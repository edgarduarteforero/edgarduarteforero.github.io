---
title: 'De Victor Hugo hacia los Large Language Models'
date: 2025-02-02
permalink: /posts/2025/02/blog-post-1/
tags:
  - ChatGPT
  - Large Language Models
  - L√≥gica
---

# De Victor Hugo hacia los Large Language Models

![Ilustraci√≥n de Victor Hugo](https://revista.marketing/images/Efemerides/Febrero_2021/26-de-febrero-1802-Nace-Victor-Hugo-ilustracion-ia-inspirada.jpg)

*Imagen tomada de [Revista Marketing](https://revista.marketing/efemerides/21-cultura/367-26-de-febrero-nace-victor-hugo). Derechos reservados a sus respectivos autores.*

En 1862, el novelista y poeta franc√©s Victor Hugo publica su maravillosa
obra ‚ÄúLos Miserables‚Äù, un relato que anima constantes debates sobre el
bien, el mal, la justicia y la ley. En uno de sus primeros episodios se
retrata la casa del obispo de Digne, cuyos √∫nicos tesoros consist√≠an en
seis cubiertos de plata, un cuchar√≥n y dos grandes candelabros de plata
maciza. Como una muestra de la humildad de este personaje, Hugo relata
que repetidamente comentaba que ‚Äúdif√≠cilmente renunciar√≠a a comer con
cubiertos que no fuesen de plata‚Äù.

Quiz√° el detallista lector pueda descifrar prontamente su significado.
Otros como yo, requerimos su revisi√≥n y algunos segundos de raz√≥n con un
an√°lisis a partir de estas tres frases:

1.  Si renuncio a comer con cubiertos que son de plata ü°™ Deseo comer con
    cubiertos de esta√±o.

2.  Si renuncio a comer con cubiertos que no son de plata ü°™ Deseo comer
    con cubiertos que son de plata.

3.  Si dif√≠cilmente renuncio a comer con cubiertos que no son de plata ü°™
    No deseo comer con cubiertos que son de plata.

Entretanto, hay quienes sin mayor meditaci√≥n balbucean que ‚Äúel obispo no
ten√≠a hambre‚Äù o que ‚Äúquer√≠a otro plato‚Äù, en muestras inherentes de
cierto letargo en la raz√≥n.

Lo cierto es que este silogismo requiere de un proceso de deconstrucci√≥n
para su comprensi√≥n. ‚ÄúDif√≠cilmente renunciar‚Äù es una doble negaci√≥n que
significa la afirmaci√≥n de aceptar. Por lo tanto, el obispo de Digne
est√° dispuesto a comer con cubiertos que no son de plata, en
concordancia con el marco de austeridad en que lo ubica Hugo.

Ahora bien, como un simple ejercicio de curiosidad, he suministrado esta
cuesti√≥n a dos aplicativos de inteligencia artificial: ChatGPT y
DeepSeek, y los resultados no son nada satisfactorios.

![Imagen3](https://github.com/user-attachments/assets/9d0828b0-af43-4467-84c4-a3a40a142a09)
<p>Respuesta generada por ChatGPT. 2025-02-02. </p>  

![Imagen2](https://github.com/user-attachments/assets/6aa9d1d7-5466-45d3-8666-76c0c089b51e)
<p>Respuesta generada por DeepSeek. 2025-02-02. </p>  

¬øPor qu√© resulta que estos dos poderosos *Large Language Models* (LLM),
capaces de construir complejos c√≥digos algor√≠tmicos, redactar ensayos
sobre filosof√≠a o construir ingeniosas campa√±as de publicidad, fallen
ante una pregunta que requiere algo de raciocinio?

Encontr√© la respuesta en la investigaci√≥n del profesor [Binghui
Peng](https://www.cs.columbia.edu/~binghuip/) de la Universidad de
Columbia, quien con su equipo de trabajo se concentr√≥ en la pregunta de
por qu√© los LLM presentan estas respuestas confusas, tambi√©n conocidas
como alucinaciones. Para comprender su trabajo debemos establecer que
este tipo de problemas son llamados ‚Äútareas de composici√≥n complejas‚Äù y
se caracterizan por que la soluci√≥n a un problema consiste en la
soluci√≥n de m√∫ltiples subproblemas que a su vez tambi√©n son resultado de
la soluci√≥n de otros subproblemas, en una compleja relaci√≥n de capas de
subproblemas. Algo muy parecido a las estrategias de soluci√≥n utilizadas
en [programaci√≥n din√°mica en el campo de la optimizaci√≥n
matem√°tica](https://en.wikipedia.org/wiki/Dynamic_programming).

Peng y su equipo lograron demostrar que los transformadores multicapa
(que vienen a ser estructuras de redes neuronales en las que se basan
los LLM) [no pueden resolver ciertas tareas de composici√≥n complejas, y
demostraron](https://arxiv.org/abs/2402.08164) que, si el n√∫mero total
de par√°metros en un transformador es menor que el tama√±o del dominio,
probablemente ese transformador no pueda resolver tareas de composici√≥n
complejas. En otras palabras, existe una limitaci√≥n matem√°tica para los
transformadores que ejecutan tareas en los LLM.

Este hallazgo es complementado con el estudio de la profesora [Nohura
Dziri](https://nouhadziri.github.io/) del Allen Institute for Artificial
Intelligence en su trabajo sobre los [l√≠mites de los transformadores en
las tareas de composici√≥n](https://arxiv.org/pdf/2305.18654) en donde se
sugiere que los transformadores LLM resuelven estas tareas mediante un
proceso de ‚Äúcomparaci√≥n linealizada de subgrafos‚Äù, sin desarrollar
necesariamente un razonamiento sistem√°tico. En s√≠ntesis, los LLM ‚Äúpueden
no ser capaces de razonar mas all√° de aquello que han visto durante las
tareas de entrenamiento con datos‚Äù.

Los cient√≠ficos buscan enfrentar estas limitantes de los LLM a trav√©s de
mecanismos que no impliquen el redise√±o de toda la arquitectura
desarrollada. T√©cnicas como las [‚Äúcadenas de pensamiento‚Äù
(chain-of-thought)](https://www.quantamagazine.org/how-chain-of-thought-reasoning-helps-neural-networks-compute-20240321/)
prometen ayudar a las redes neuronales a resolver problemas de este
tipo.

Para finalizar, el profesor Anil Ananthaswamy, autor del [art√≠culo sobre
el que baso este
post](https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/)
pone las cosas en su lugar. Mientras que la gran mayor√≠a de usuarios
continuar√°n utilizando los LLM para resolver tareas sencillas que
facilitan su productividad, otros en la comunidad cient√≠fica buscan
comprender ‚Äúqu√© es lo que sucede tras bambalinas‚Äù y c√≥mo se dan esos
procesos de soluci√≥n de tareas con interrogantes acerca del ‚Äúc√≥mo lo
hacen‚Äù antes de ‚Äúqu√© es lo que hacen‚Äù.

Mientras tanto, me atrevo a afirmar que ‚Äúcon gran pesar aceptar√≠a la
posibilidad de no preferir abiertamente que Los miserables contin√∫e
planteando interrogantes que ahora van m√°s desde los no prohibidos
espacios de la justicia, la √©tica y la moral, hacia el abierto uso y sin
desd√©n en los campos de la ciencia de la informaci√≥n‚Äù.

